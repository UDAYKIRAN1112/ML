{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b74d88c4-3863-433d-9a56-e5d494637d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61b58768-374e-41f7-9354-762e77a194b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     outlook temperature  humidity   wind class\n",
      "0    outlook        temp  humidity  windy  play\n",
      "1      sunny         hot      high  false    no\n",
      "2      sunny         hot      high   true    no\n",
      "3   overcast         hot      high  false   yes\n",
      "4      rainy        mild      high  false   yes\n",
      "5      rainy        cool    normal  false   yes\n",
      "6      rainy        cool    normal   true    no\n",
      "7   overcast        cool    normal   true   yes\n",
      "8      sunny        mild      high  false    no\n",
      "9      sunny        cool    normal  false   yes\n",
      "10     rainy        mild    normal  false   yes\n",
      "11     sunny        mild    normal   true   yes\n",
      "12  overcast        mild      high   true   yes\n",
      "13  overcast         hot    normal  false   yes\n",
      "14     rainy        mild      high   true    no\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv('playTennis.csv',names=['outlook','temperature','humidity','wind','class'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d13cba1e-a8ed-4475-a645-9c7bb5d2ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    elements,counts=np.unique(target_col,return_counts=True)\n",
    "    entropy=np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e592c75-228e-4dba-8849-9f880da53d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
    "    total_entropy=entropy(data[target_name])\n",
    "    vals,counts=np.unique(data[split_attribute_name],return_counts=True)\n",
    "    Weighted_Entropy=np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    Information_Gain=total_entropy-Weighted_Entropy\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5a88e92-6dde-4fb2-91ad-8885ef4a843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class=None):\n",
    "    if len(np.unique(data[target_attribute_name]))<=1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    elif len(features)==0:\n",
    "        return parent_node_class\n",
    "    else:\n",
    "        parent_node_class=np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        item_values=[InfoGain(data,feature,target_attribute_name) for feature in features]\n",
    "        best_feature_index=np.argmax(item_values)\n",
    "        best_feature=features[best_feature_index]\n",
    "        tree={best_feature:{}}\n",
    "        features=[i for i in features if i!=best_feature]\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value=value\n",
    "            sub_data=data.where(data[best_feature]==value).dropna()\n",
    "            subtree=ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
    "            tree[best_feature][value]=subtree\n",
    "        return (tree)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db0c0b55-d49b-4d4f-a50c-73daeb1b5243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Display Tree:\n",
      " {'outlook': {'outlook': 'play', 'overcast': 'yes', 'rainy': {'wind': {'false': 'yes', 'true': 'no'}}, 'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "tree=ID3(dataset,dataset,dataset.columns[:-1])\n",
    "print('\\n Display Tree:\\n',tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f2a6b2-c5b4-4097-988c-19c714d3f136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0e8d4-30c8-4c95-a998-98b6daed163b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a32ad1a-a8f3-4c0a-9a49-73950ba93316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low risk of heart disease with probability: 0.00\n",
      "+----------------------------------+---------------------+\n",
      "| heartdisease                     |   phi(heartdisease) |\n",
      "+==================================+=====================+\n",
      "| heartdisease(0.0)                |              0.4414 |\n",
      "+----------------------------------+---------------------+\n",
      "| heartdisease(0.5445544554455446) |              0.0000 |\n",
      "+----------------------------------+---------------------+\n",
      "| heartdisease(1.0)                |              0.5586 |\n",
      "+----------------------------------+---------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KBinsDiscretizer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Load the dataset\n",
    "names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'heartdisease']\n",
    "heartDisease = pd.read_csv('heart.csv', names = names)\n",
    "heartDisease = heartDisease.replace('?', np.nan)\n",
    "\n",
    "# Replace missing values marked as '?' with NaN and handle them\n",
    "heartDisease = heartDisease.apply(pd.to_numeric, errors='coerce')\n",
    "heartDisease.fillna(heartDisease.mean(), inplace=True)\n",
    "\n",
    "# Discretize continuous variables\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "heartDisease['age'] = discretizer.fit_transform(heartDisease[['age']])\n",
    "heartDisease['trestbps'] = discretizer.fit_transform(heartDisease[['trestbps']])\n",
    "heartDisease['chol'] = discretizer.fit_transform(heartDisease[['chol']])\n",
    "heartDisease['thalach'] = discretizer.fit_transform(heartDisease[['thalach']])\n",
    "\n",
    "\n",
    "# Define the structure of the Bayesian Network\n",
    "model = BayesianNetwork([\n",
    "    ('age', 'trestbps'), \n",
    "    ('age', 'fbs'), \n",
    "    ('sex', 'trestbps'), \n",
    "    ('exang', 'trestbps'),\n",
    "    ('trestbps', 'heartdisease'), \n",
    "    ('fbs', 'heartdisease'), \n",
    "    ('heartdisease', 'restecg'), \n",
    "    ('heartdisease', 'thalach'), \n",
    "    ('heartdisease', 'chol')\n",
    "])\n",
    "\n",
    "# Fit the model using Maximum Likelihood Estimator\n",
    "model.fit(heartDisease, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Perform inference\n",
    "infer = VariableElimination(model)\n",
    "\n",
    "# Example: Diagnose heart disease for a patient with specific attributes\n",
    "# Discretize the age value to match the model\n",
    "age_value = 37\n",
    "discretized_age = int(discretizer.transform([[age_value]])[0][0])\n",
    "\n",
    "evidence = {'age': discretized_age}\n",
    "\n",
    "try:\n",
    "    q = infer.query(variables=['heartdisease'], evidence=evidence)\n",
    "\n",
    "    # Extract the probability of having heart disease\n",
    "    prob_heart_disease = q.values[1]  # Assuming 1 indicates presence of heart disease\n",
    "\n",
    "    # Use if-else statements to make decisions based on the probability\n",
    "    if prob_heart_disease > 0.5:\n",
    "        print(f\"High risk of heart disease with probability: {prob_heart_disease:.2f}\")\n",
    "    else:\n",
    "        print(f\"Low risk of heart disease with probability: {prob_heart_disease:.2f}\")\n",
    "\n",
    "    # Print the entire distribution for more information\n",
    "    print(q)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3076327-728e-4414-a0d9-f82d81b202f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88466b60-2fa9-4691-9287-d170da152709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
